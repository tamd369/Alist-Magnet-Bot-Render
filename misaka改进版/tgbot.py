import requests
import sys
import re
import logging
import os
import asyncio
import ast
import math
import html
from datetime import datetime

from dotenv import load_dotenv
from functools import wraps

from telegram import Update
from telegram.constants import ParseMode, ChatAction
from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes

# åŠ è½½ .env æ–‡ä»¶ä¸­çš„ç¯å¢ƒå˜é‡
load_dotenv()

# é…ç½®æ—¥å¿—
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger(__name__)

# --- ä»ç¯å¢ƒå˜é‡åŠ è½½é…ç½® ---
TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN")
BASE_URL = os.getenv("ALIST_BASE_URL")
USERNAME = os.getenv("ALIST_USERNAME")
PASSWORD = os.getenv("ALIST_PASSWORD")
OFFLINE_DOWNLOAD_DIR = os.getenv("ALIST_OFFLINE_DIR")
SEARCH_URL = os.getenv("JAV_SEARCH_API")
ALLOWED_USER_IDS_STR = os.getenv("ALLOWED_USER_IDS")

# --- é…ç½®æ ¡éªŒ ---
if not all([TELEGRAM_TOKEN, BASE_URL, USERNAME, PASSWORD, OFFLINE_DOWNLOAD_DIR, SEARCH_URL, ALLOWED_USER_IDS_STR]):
    logger.error("é”™è¯¯ï¼šç¯å¢ƒå˜é‡ç¼ºå¤±ï¼è¯·æ£€æŸ¥ .env æ–‡ä»¶æˆ–ç¯å¢ƒå˜é‡è®¾ç½®ã€‚")
    sys.exit(1)

try:
    # å°†é€—å·åˆ†éš”çš„å­—ç¬¦ä¸²è½¬æ¢ä¸ºæ•´æ•°é›†åˆ
    ALLOWED_USER_IDS = set(map(int, ALLOWED_USER_IDS_STR.split(',')))
    logger.info(f"å…è®¸çš„ç”¨æˆ· ID: {ALLOWED_USER_IDS}")
except ValueError:
    logger.error("é”™è¯¯: ALLOWED_USER_IDS æ ¼å¼ä¸æ­£ç¡®ï¼Œè¯·ç¡®ä¿æ˜¯é€—å·åˆ†éš”çš„æ•°å­—ã€‚")
    sys.exit(1)


# --- å…¨å±€tokenç¼“å­˜ ---
# ä½¿ç”¨ context.bot_data æ¥å­˜å‚¨ tokenï¼Œæ›´é€‚åˆ PTB v20+
# global_token = None # ä¸å†ä½¿ç”¨å…¨å±€å˜é‡

# --- ç”¨æˆ·æˆæƒè£…é¥°å™¨ ---
def restricted(func):
    @wraps(func)
    async def wrapped(update: Update, context: ContextTypes.DEFAULT_TYPE, *args, **kwargs):
        user_id = update.effective_user.id
        if user_id not in ALLOWED_USER_IDS:
            logger.warning(f"æœªæˆæƒç”¨æˆ·å°è¯•è®¿é—®: {user_id}")
            await update.message.reply_text("æŠ±æ­‰ï¼Œæ‚¨æ²¡æœ‰æƒé™ä½¿ç”¨æ­¤æœºå™¨äººã€‚")
            return
        # æ£€æŸ¥å¹¶è·å– tokenï¼Œå­˜å‚¨åœ¨ bot_data ä¸­
        token = await get_token(context)
        if not token:
             await update.message.reply_text("é”™è¯¯: æ— æ³•è¿æ¥æˆ–ç™»å½•åˆ° Alist æœåŠ¡ã€‚")
             return
        # å°† token ä¼ é€’ç»™å¤„ç†å‡½æ•°
        return await func(update, context, token=token, *args, **kwargs)
    return wrapped

# --- API å‡½æ•° ---

def parse_size_to_bytes(size_str: str) -> int | None:
    """Converts size string (e.g., '5.40GB', '1.25MB') to bytes."""
    if not size_str:
        return 0 # Treat empty size as 0 bytes

    size_str = size_str.upper()
    match = re.match(r'^([\d.]+)\s*([KMGTPEZY]?B)$', size_str)
    if not match:
        logger.warning(f"æ— æ³•è§£ææ–‡ä»¶å¤§å°: {size_str}")
        return None # Indicate parsing failure

    value, unit = match.groups()
    try:
        value = float(value)
    except ValueError:
        logger.warning(f"æ— æ³•è§£ææ–‡ä»¶å¤§å°å€¼: {value} from {size_str}")
        return None

    unit = unit.upper()
    exponent = 0
    if unit.startswith('K'):
        exponent = 1
    elif unit.startswith('M'):
        exponent = 2
    elif unit.startswith('G'):
        exponent = 3
    elif unit.startswith('T'):
        exponent = 4
    # Add more if needed (P, E, Z, Y)

    return int(value * (1024 ** exponent))

# --- Helper Function to Parse Data Entry ---
def parse_api_data_entry(entry_str: str) -> dict | None:
    """Parses a single string entry from the API data list."""
    try:
        # Safely evaluate the string representation of the list
        data_list = ast.literal_eval(entry_str)
        if not isinstance(data_list, list) or len(data_list) < 4:
            logger.warning(f"è§£æåçš„æ•°æ®æ ¼å¼ä¸æ­£ç¡® (éåˆ—è¡¨æˆ–é•¿åº¦ä¸è¶³): {data_list}")
            return None

        magnet = data_list[0]
        name = data_list[1]
        size_str = data_list[2]
        date_str = data_list[3] # YYYY-MM-DD

        if not magnet or not magnet.startswith("magnet:?"):
            logger.warning(f"æ¡ç›®ä¸­ç¼ºå°‘æœ‰æ•ˆçš„ç£åŠ›é“¾æ¥: {entry_str}")
            return None

        size_bytes = parse_size_to_bytes(size_str)
        if size_bytes is None: # Handle parsing failure
             logger.warning(f"æ— æ³•è§£æå¤§å°ï¼Œè·³è¿‡æ¡ç›®: {entry_str}")
             return None # Skip entry if size is unparseable

        # Parse date safely
        upload_date = None
        try:
            if date_str:
                upload_date = datetime.strptime(date_str, '%Y-%m-%d').date()
        except ValueError:
            logger.warning(f"æ— æ³•è§£ææ—¥æœŸ '{date_str}'ï¼Œæ—¥æœŸå°†ä¸º None")


        return {
            "magnet": magnet,
            "name": name,
            "size_str": size_str,
            "size_bytes": size_bytes,
            "date_str": date_str,
            "date": upload_date,
            "original_string": entry_str # Keep original for logging if needed
        }

    except (ValueError, SyntaxError, TypeError) as e:
        logger.error(f"è§£æ API æ•°æ®æ¡ç›®æ—¶å‡ºé”™: '{entry_str[:100]}...', é”™è¯¯: {e}")
        return None

def get_magnet(fanhao, search_url):
    try:
        url = search_url.rstrip('/') + "/" + fanhao
        logger.info(f"æ­£åœ¨æœç´¢ç•ªå·: {fanhao} ä½¿ç”¨ URL: {url}")
        response = requests.get(url, timeout=20)
        response.raise_for_status()

        try:
            raw_result = response.json()
            logger.debug(f"API åŸå§‹å“åº”æ–‡æœ¬ ({fanhao}): {response.text}")
            logger.debug(f"API è§£æåçš„ JSON ({fanhao}): {raw_result}")
        except requests.exceptions.JSONDecodeError:
            logger.error(f"é”™è¯¯: API ({url}) è¿”å›çš„ä¸æ˜¯æœ‰æ•ˆçš„ JSONã€‚å“åº”å†…å®¹: {response.text}")
            return None, "æœç´¢æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ (è¿”å›æ ¼å¼é”™è¯¯)"

        if not raw_result or raw_result.get("status") != "succeed" or not raw_result.get("data") or not isinstance(raw_result.get("data"), list) or len(raw_result["data"]) == 0:
            logger.warning(f"API å“åº”æœªé€šè¿‡æˆåŠŸæ¡ä»¶æ£€æŸ¥æˆ–æœªæ‰¾åˆ°ç»“æœ ({fanhao}). Data: {raw_result}")
            error_msg = raw_result.get('message', 'æœªçŸ¥APIé”™è¯¯') if isinstance(raw_result, dict) else 'å“åº”æ ¼å¼é”™è¯¯'
            if raw_result and raw_result.get("status") != "succeed":
                 return None, f"æœç´¢æœåŠ¡æŠ¥å‘Šé”™è¯¯ (çŠ¶æ€: {raw_result.get('status', 'æœªçŸ¥')})"
            else:
                 return None, f"æœªèƒ½æ‰¾åˆ°ç•ªå· '{fanhao}' å¯¹åº”çš„èµ„æº"

        # --- Magnet Selection Logic ---
        parsed_entries = []
        for entry_str in raw_result["data"]:
            parsed = parse_api_data_entry(entry_str)
            if parsed:
                parsed_entries.append(parsed)

        if not parsed_entries:
            logger.error(f"é”™è¯¯: æˆåŠŸè·å– API æ•°æ®ï¼Œä½†æ— æ³•è§£æä»»ä½•æœ‰æ•ˆæ¡ç›® ({fanhao})")
            return None, "æ‰¾åˆ°äº†èµ„æºï¼Œä½†æ— æ³•è§£æå…¶è¯¦ç»†ä¿¡æ¯"

        # Find max size for clustering heuristic
        max_size = 0
        for entry in parsed_entries:
             if entry["size_bytes"] > max_size:
                 max_size = entry["size_bytes"]

        if max_size == 0: # Handle case where all sizes are 0 or unparseable
             logger.warning(f"æ— æ³•ç¡®å®šæœ€å¤§æ–‡ä»¶å¤§å°ï¼Œå°†ä½¿ç”¨ç¬¬ä¸€ä¸ªæœ‰æ•ˆç£é“¾ ({fanhao})")
             return parsed_entries[0]["magnet"], None # Fallback: return the first one found


	# å®šä¹‰ HD é›†ç¾¤é˜ˆå€¼ï¼ˆä¾‹å¦‚ï¼Œ> æœ€å¤§å°ºå¯¸çš„ 70%ï¼‰
	# å¦‚æœéœ€è¦ï¼Œæ ¹æ®å…¸å‹çš„å°ºå¯¸å·®å¼‚è°ƒæ•´æ­¤é˜ˆå€¼ (0.7)
        hd_threshold = max_size * 0.7
        hd_cluster = [entry for entry in parsed_entries if entry["size_bytes"] >= hd_threshold]

        selected_cluster = hd_cluster
        if not hd_cluster:
            logger.info(f"æœªæ‰¾åˆ°æ˜æ˜¾çš„é«˜æ¸…ç‰ˆæœ¬ (å¤§å° > {hd_threshold / (1024**3):.2f} GB)ï¼Œå°†åœ¨æ‰€æœ‰ç‰ˆæœ¬ä¸­é€‰æ‹© ({fanhao})")
            selected_cluster = parsed_entries # Fallback to all entries if no HD cluster

        if not selected_cluster: # Should not happen if parsed_entries was not empty, but safety check
             logger.error(f"é”™è¯¯: æ— æ³•ç¡®å®šé€‰æ‹©é›†ç¾¤ ({fanhao})")
             return None, "ç­›é€‰ç£åŠ›é“¾æ¥æ—¶å‡ºé”™"

		# å¯¹æ‰€é€‰é›†ç¾¤è¿›è¡Œæ’åºï¼š
		# 1. å°ºå¯¸æœ€å°çš„ä¼˜å…ˆï¼ˆåœ¨é›†ç¾¤å†…ï¼‰
		# 2. æ—¥æœŸæœ€æ–°çš„ä¼˜å…ˆï¼ˆä½œä¸ºå¹¶åˆ—é¡¹çš„æ‰“ç ´è§„åˆ™ - æŒ‰ç…§ç¤ºä¾‹åˆ†æä½¿ç”¨æœ€æ–°çš„ï¼‰
		#    å¯¹äºæ²¡æœ‰æ—¥æœŸçš„æ¡ç›®ï¼Œä½¿ç”¨éå¸¸æ—§çš„æ—¥æœŸï¼Œä»¥ä¾¿å®ƒä»¬åœ¨å¹¶åˆ—æ‰“ç ´è§„åˆ™ä¸­æ’åœ¨æœ€åã€‚
        epoch_start_date = datetime(1970, 1, 1).date()
        selected_cluster.sort(key=lambda x: (x["size_bytes"], -(x["date"].toordinal() if x["date"] else epoch_start_date.toordinal())))


        chosen_entry = selected_cluster[0]
        chosen_magnet = chosen_entry["magnet"]

        logger.info(f"æ™ºèƒ½é€‰æ‹©å®Œæˆ ({fanhao}):")
        logger.info(f" - æ€»å…±è§£ææ¡ç›®: {len(parsed_entries)}")
        logger.info(f" - æœ€å¤§æ£€æµ‹å¤§å°: {max_size / (1024**3):.2f} GB")
        if hd_cluster:
            logger.info(f" - é«˜æ¸…é›†ç¾¤æ¡ç›®æ•° (> {hd_threshold / (1024**3):.2f} GB): {len(hd_cluster)}")
        logger.info(f" - é€‰æ‹©æ ‡å‡†: {'é«˜æ¸…é›†ç¾¤' if hd_cluster else 'æ‰€æœ‰ç‰ˆæœ¬'}å†…ï¼Œä¼˜å…ˆæœ€å°ä½“ç§¯ï¼Œå…¶æ¬¡æœ€æ–°æ—¥æœŸ")
        logger.info(f" - æœ€ç»ˆé€‰æ‹©: {chosen_entry['name']} ({chosen_entry['size_str']}, {chosen_entry['date_str']})")
        logger.info(f" - ç£åŠ›é“¾æ¥: {chosen_magnet[:60]}...")

        return chosen_magnet, None
        # --- End Magnet Selection Logic ---

    except requests.exceptions.Timeout:
        logger.error(f"è·å–ç£åŠ›é“¾æ¥æ—¶è¶…æ—¶ ({fanhao})")
        return None, "æœç´¢ç•ªå·è¶…æ—¶ï¼Œè¯·ç¨åå†è¯•"
    except requests.exceptions.RequestException as e:
        logger.error(f"è·å–ç£åŠ›é“¾æ¥æ—¶ç½‘ç»œå‡ºé”™ ({fanhao}): {str(e)}")
        return None, "æœç´¢æœåŠ¡è¿æ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œæˆ–ç¨åå†è¯•"
    except Exception as e:
        logger.error(f"è·å–ç£åŠ›é“¾æ¥æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯ ({fanhao}): {str(e)}", exc_info=True)
        return None, "æœç´¢è¿‡ç¨‹ä¸­å‘ç”Ÿå†…éƒ¨é”™è¯¯"

async def get_token(context: ContextTypes.DEFAULT_TYPE) -> str | None:
    """è·å– Alist Tokenï¼Œä¼˜å…ˆä» context.bot_data è·å–ï¼Œå¦åˆ™ç™»å½•è·å–"""
    bot_data = context.bot_data
    token = bot_data.get("alist_token")

    if token:
        # å¯é€‰ï¼šåœ¨è¿™é‡Œæ·»åŠ ä¸€ä¸ªç®€å•çš„æµ‹è¯•è¯·æ±‚æ¥éªŒè¯ token æ˜¯å¦ä»ç„¶æœ‰æ•ˆ
        # å¦‚æœæ— æ•ˆï¼Œè®¾ç½® token = Noneï¼Œå¼ºåˆ¶é‡æ–°ç™»å½•
        logger.info("ä½¿ç”¨ç¼“å­˜çš„ Alist token")
        return token

    try:
        url = BASE_URL.rstrip('/') + "/api/auth/login"
        logger.info("ç¼“å­˜ token æ— æ•ˆæˆ–ä¸å­˜åœ¨ï¼Œæ­£åœ¨ç™»å½•è·å–æ–°çš„ Alist token...")
        login_info = {"username": USERNAME, "password": PASSWORD}
        loop = asyncio.get_running_loop() # è·å–å½“å‰äº‹ä»¶å¾ªç¯
        response = await loop.run_in_executor( 
            None, # ä½¿ç”¨é»˜è®¤çš„ executor
            lambda: requests.post(url, json=login_info, timeout=15)
        )
        response.raise_for_status()

        result = response.json()
        if result.get("code") == 200 and result.get("data") and result["data"].get("token"):
            token = str(result['data']['token'])
            logger.info("ç™»å½• Alist æˆåŠŸï¼Œå·²è·å–å¹¶ç¼“å­˜ token")
            bot_data["alist_token"] = token  # ç¼“å­˜ token
            return token
        else:
            error_msg = result.get('message', 'æœªçŸ¥é”™è¯¯')
            logger.error(f"Alist ç™»å½•å¤±è´¥: {error_msg} (Code: {result.get('code', 'N/A')})")
            return None
    except requests.exceptions.RequestException as e:
        logger.error(f"ç™»å½• Alist è·å– token æ—¶å‡ºé”™: {str(e)}")
        return None
    except Exception as e:
        logger.error(f"ç™»å½• Alist è¿‡ç¨‹ä¸­å‘ç”ŸæœªçŸ¥é”™è¯¯: {str(e)}", exc_info=True)
        return None

async def add_magnet(context: ContextTypes.DEFAULT_TYPE, token: str, magnet: str) -> tuple[bool, str]:
    """ä½¿ç”¨ 'storage' å·¥å…·æ·»åŠ ç£åŠ›é“¾æ¥åˆ° Alist ç¦»çº¿ä¸‹è½½"""
    if not token or not magnet:
        logger.error("é”™è¯¯: token æˆ–ç£åŠ›é“¾æ¥ä¸ºç©º")
        # è¿”å›ç¬¦åˆ (bool, str) æ ¼å¼çš„é”™è¯¯ä¿¡æ¯
        return False, "å†…éƒ¨é”™è¯¯ï¼šToken æˆ–ç£åŠ›é“¾æ¥ä¸ºç©º"

    try:
        # ä½¿ç”¨å…¨å±€å˜é‡ BASE_URL å’Œ OFFLINE_DOWNLOAD_DIR
        url = BASE_URL.rstrip('/') + "/api/fs/add_offline_download"
        logger.info(f"æ­£åœ¨æ·»åŠ ç¦»çº¿ä¸‹è½½ä»»åŠ¡åˆ°ç›®å½•: {OFFLINE_DOWNLOAD_DIR}")

        headers = {
            "Authorization": token,
            "Content-Type": "application/json"
        }
        # --- ä¿®æ”¹ post_data ---
        post_data = {
            "path": OFFLINE_DOWNLOAD_DIR,
            "urls": [magnet],
            "tool": "storage",  # <--- è¿™é‡Œä¿®æ”¹ä¸º "storage"
            "delete_policy": "delete_on_upload_succeed" # å’Œä½ æä¾›çš„ç¤ºä¾‹ä¸€è‡´
        }
        # --- ä¿®æ”¹ç»“æŸ ---

        loop = asyncio.get_running_loop() # è·å–å½“å‰äº‹ä»¶å¾ªç¯
        # --- ä¿ç•™å¼‚æ­¥æ‰§è¡Œ ---
        response = await loop.run_in_executor(
             None, # ä½¿ç”¨é»˜è®¤çš„ executor
             lambda: requests.post(url, json=post_data, headers=headers, timeout=30) # å¢åŠ è¶…æ—¶æ—¶é—´
        )
        # --- å¼‚æ­¥æ‰§è¡Œç»“æŸ ---

        if response.status_code == 401:
            logger.warning("Alist token å¯èƒ½å·²è¿‡æœŸæˆ–æ— æ•ˆ (æ”¶åˆ° 401)")
            context.bot_data.pop("alist_token", None)
            # ç”¨æˆ·å‹å¥½çš„é”™è¯¯
            return False, "âŒ Alist è®¤è¯å¤±è´¥ï¼ŒToken å¯èƒ½å·²è¿‡æœŸï¼Œè¯·ç¨åé‡è¯•"

        response.raise_for_status()
        result = response.json()

        if result.get("code") == 200:
            logger.info("ç¦»çº¿ä¸‹è½½ä»»åŠ¡æ·»åŠ æˆåŠŸ!")
            # æˆåŠŸçš„æ¶ˆæ¯
            return True, "âœ… ç¦»çº¿ä¸‹è½½ä»»åŠ¡æ·»åŠ æˆåŠŸï¼"
        else:
            error_msg = result.get('message', 'æœªçŸ¥é”™è¯¯')
            logger.error(f"æ·»åŠ  Alist ç¦»çº¿ä¸‹è½½ä»»åŠ¡å¤±è´¥: {error_msg} (Code: {result.get('code', 'N/A')})")
            # ç”¨æˆ·å‹å¥½çš„é”™è¯¯ - ä» Alist API è·å–çš„æ¶ˆæ¯å¯èƒ½å·²ç»æ¯”è¾ƒæ¸…æ™°
            return False, f"âŒ æ·»åŠ ä»»åŠ¡å¤±è´¥: {error_msg}"

    except requests.exceptions.Timeout:
        logger.error("æ·»åŠ  Alist ç¦»çº¿ä¸‹è½½ä»»åŠ¡æ—¶è¶…æ—¶")
        # ç”¨æˆ·å‹å¥½çš„é”™è¯¯
        return False, "âŒ æ·»åŠ ä»»åŠ¡è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ Alist æœåŠ¡çŠ¶æ€"
    except requests.exceptions.RequestException as e:
        logger.error(f"æ·»åŠ  Alist ç¦»çº¿ä¸‹è½½ä»»åŠ¡æ—¶å‡ºé”™: {str(e)}")
        if "Connection refused" in str(e) or "Failed to establish a new connection" in str(e):
             # ç”¨æˆ·å‹å¥½çš„é”™è¯¯
             return False, "âŒ æ·»åŠ ä»»åŠ¡å¤±è´¥: æ— æ³•è¿æ¥åˆ° Alist æœåŠ¡ï¼Œè¯·æ£€æŸ¥å…¶æ˜¯å¦è¿è¡Œ"
        # ç”¨æˆ·å‹å¥½çš„é”™è¯¯
        return False, f"âŒ æ·»åŠ ä»»åŠ¡æ—¶ç½‘ç»œå‡ºé”™: è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ– Alist åœ°å€"
    except Exception as e:
        logger.error(f"æ·»åŠ  Alist ç¦»çº¿ä¸‹è½½ä»»åŠ¡æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {str(e)}", exc_info=True)
        # ç”¨æˆ·å‹å¥½çš„é”™è¯¯
        return False, "âŒ æ·»åŠ ä»»åŠ¡æ—¶å‘ç”Ÿå†…éƒ¨é”™è¯¯"

async def find_download_directory(token: str, base_url: str, parent_dir: str, original_code: str) -> tuple[str | None, str | None]:
    """
    Searches for a directory within parent_dir that matches the original_code.

    Args:
        token: Alist auth token.
        base_url: Alist base URL.
        parent_dir: The base directory where downloads are stored (e.g., OFFLINE_DOWNLOAD_DIR).
        original_code: The code provided by the user (e.g., 'SONE-622').

    Returns:
        tuple[str | None, str | None]: (found_path, error_message)
        - If exactly one match is found, returns (full_path, None).
        - If no matches or multiple matches are found, or an error occurs, returns (None, error_message).
    """
    logger.info(f"åœ¨ '{parent_dir}' ä¸­æœç´¢ä¸ '{original_code}' åŒ¹é…çš„ç›®å½•...")
    list_url = base_url.rstrip('/') + "/api/fs/list"
    headers = {"Authorization": token, "Content-Type": "application/json"}
    list_payload = {"path": parent_dir, "page": 1, "per_page": 0} # Get all items

    try:
        loop = asyncio.get_running_loop()
        response_list = await loop.run_in_executor(
            None, lambda: requests.post(list_url, json=list_payload, headers=headers, timeout=20)
        )
        response_list.raise_for_status()
        list_result = response_list.json()

        if list_result.get("code") != 200 or not list_result.get("data") or list_result["data"].get("content") is None:
            msg = f"æ— æ³•åˆ—å‡ºçˆ¶ç›®å½• '{parent_dir}' çš„å†…å®¹: {list_result.get('message', 'æœªçŸ¥é”™è¯¯')}"
            logger.error(msg)
            return None, msg

        content = list_result["data"]["content"]
        if not content:
            msg = f"çˆ¶ç›®å½• '{parent_dir}' ä¸ºç©ºæˆ–æ— æ³•è®¿é—®ã€‚"
            logger.warning(msg)
            return None, msg

        possible_matches = []
        lower_code = original_code.lower()

        for item in content:
            if item.get("is_dir"):
                dir_name = item.get("name")
                if dir_name:
                    # Match if the directory name starts with the code (case-insensitive)
                    if dir_name.lower().startswith(lower_code):
                        # Construct the full path for the match
                        full_path = parent_dir.rstrip('/') + '/' + dir_name
                        possible_matches.append({"name": dir_name, "path": full_path})
                        logger.debug(f"æ‰¾åˆ°æ½œåœ¨åŒ¹é…ç›®å½•: {full_path}")

        if len(possible_matches) == 1:
            found = possible_matches[0]
            logger.info(f"æ‰¾åˆ°å”¯ä¸€åŒ¹é…ç›®å½•: {found['path']}")
            return found['path'], None
        elif len(possible_matches) == 0:
            msg = f"åœ¨ '{parent_dir}' ä¸­æœªæ‰¾åˆ°ä»»ä½•ä»¥ '{original_code}' å¼€å¤´çš„ç›®å½•ã€‚"
            logger.warning(msg)
            return None, msg
        else:
            match_names = [m['name'] for m in possible_matches]
            msg = f"æ‰¾åˆ°å¤šä¸ªå¯èƒ½çš„ç›®å½•: {match_names}ã€‚è¯·ç¡®è®¤å…·ä½“æ˜¯å“ªä¸€ä¸ªæˆ–æ‰‹åŠ¨æ¸…ç†ã€‚"
            logger.warning(msg)
            return None, msg

    except requests.exceptions.Timeout:
        msg = f"æŸ¥æ‰¾ç›®å½•æ—¶è¯·æ±‚è¶…æ—¶ (ä¸ Alist é€šä¿¡æ—¶)"
        logger.error(msg)
        return None, msg
    except requests.exceptions.RequestException as e:
        msg = f"æŸ¥æ‰¾ç›®å½•æ—¶å‘ç”Ÿç½‘ç»œé”™è¯¯: {e}"
        logger.error(msg)
        return None, msg
    except Exception as e:
        msg = f"æŸ¥æ‰¾ç›®å½•æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}"
        logger.error(msg, exc_info=True)
        return None, msg


# --- å¹¿å‘Šæ–‡ä»¶æ¸…ç†å‡½æ•° ---

# å®šä¹‰å¹¿å‘Šæ–‡ä»¶çš„æ¨¡å¼å’Œå…³é”®è¯
# æ ¹æ®è§‚å¯Ÿï¼Œä½¿è¿™äº›å†…å®¹æ›´å…¨é¢
AD_KEYWORDS = ["ç›´æ’­", "èšåˆ", "ç¤¾åŒº", "æƒ…æŠ¥", "æœ€æ–°åœ°å€", "ç²å–", "èŠ±å¼è¡¨æ¼”", "å¤§å…¨", "ç¾¤æ·«å‚³", "ä¸‰åœ‹å¿—Hç‰ˆ", "ä¸ƒé¾ç Hç‰ˆ"] # Add more common ad phrases
AD_DOMAINS = ["996gg.cc"] # Add known ad domains found in filenames
AD_EXTENSIONS = {".txt", ".html", ".htm", ".url", ".lnk", ".apk", ".exe"} # Extensions often used for ads/junk
MEDIA_EXTENSIONS = {".mp4", ".mkv", ".avi", ".wmv", ".mov", ".flv", ".rmvb"} # Common video extensions to keep

async def cleanup_ad_files(token: str, base_url: str, directory_path: str, original_code: str):
    """
    Lists files in a directory via Alist API, identifies, and deletes ad files.
    Args:
        token: Alist auth token.
        base_url: Alist base URL.
        directory_path: The path within Alist where the download finished.
        original_code: The original search code (e.g., 'SONE-622') used for identifying main files.
    Returns:
        tuple[bool, str]: (success_status, message)
    """
    logger.info(f"å¼€å§‹æ¸…ç†ç›®å½• '{directory_path}' ä¸­çš„å¹¿å‘Šæ–‡ä»¶ (åŸºäºç•ªå·: {original_code})")

    list_url = base_url.rstrip('/') + "/api/fs/list"
    remove_url = base_url.rstrip('/') + "/api/fs/remove"
    headers = {"Authorization": token, "Content-Type": "application/json"}

    try:
        # 1. List files in the directory
        list_payload = {"path": directory_path, "page": 1, "per_page": 0} # Get all files
        loop = asyncio.get_running_loop()
        response_list = await loop.run_in_executor(
            None, lambda: requests.post(list_url, json=list_payload, headers=headers, timeout=20)
        )
        response_list.raise_for_status()
        list_result = response_list.json()

        if list_result.get("code") != 200 or not list_result.get("data") or list_result["data"].get("content") is None:
            msg = f"æ— æ³•åˆ—å‡ºç›®å½• '{directory_path}' çš„å†…å®¹: {list_result.get('message', 'æœªçŸ¥é”™è¯¯')}"
            logger.error(msg)
            return False, f"âŒ æ¸…ç†å¤±è´¥: {msg}"

        files_to_check = list_result["data"]["content"]
        if not files_to_check:
            logger.info(f"ç›®å½• '{directory_path}' ä¸ºç©ºï¼Œæ— éœ€æ¸…ç†ã€‚")
            return True, "âœ… ç›®å½•ä¸ºç©ºï¼Œæ— éœ€æ¸…ç†ã€‚"

        # Prepare original code for matching (lowercase, remove hyphen for broader match)
        match_code = original_code.lower().replace('-', '')

        files_to_delete = []
        files_kept = []

        # 2. Identify files to delete
        for file_info in files_to_check:
            if file_info.get("is_dir"): # Skip directories
                continue

            filename = file_info.get("name")
            if not filename:
                continue

            base_name, extension = os.path.splitext(filename)
            extension = extension.lower()
            lower_filename = filename.lower()
            lower_basename = base_name.lower()

            # Rule 1: Check if it's a primary media file to KEEP
            keep_file = False
            if extension in MEDIA_EXTENSIONS:
                # Check if filename contains the essential code part
                # (e.g., 'sone622' is in 'sone-622ch.mp4')
                # Make matching more robust if needed (e.g., allow only prefix/suffix)
                if match_code in lower_basename.replace('-', ''):
                    keep_file = True
                    files_kept.append(filename)
                    logger.debug(f"ä¿ç•™ä¸»åª’ä½“æ–‡ä»¶: {filename}")

            # Rule 2: If not explicitly kept, check if it matches AD criteria
            delete_file = False
            if not keep_file:
                if extension in AD_EXTENSIONS:
                    delete_file = True
                    logger.debug(f"æ ‡è®°åˆ é™¤ (å¹¿å‘Šæ‰©å±•å): {filename}")
                elif any(keyword in filename for keyword in AD_KEYWORDS): # Check full name for keywords
                    delete_file = True
                    logger.debug(f"æ ‡è®°åˆ é™¤ (å¹¿å‘Šå…³é”®è¯): {filename}")
                elif any(domain in lower_filename for domain in AD_DOMAINS):
                    delete_file = True
                    logger.debug(f"æ ‡è®°åˆ é™¤ (å¹¿å‘ŠåŸŸå): {filename}")
                # Add more specific rules if needed

            if delete_file:
                files_to_delete.append(filename)

        if not files_to_delete:
            logger.info(f"åœ¨ '{directory_path}' ä¸­æœªæ‰¾åˆ°éœ€è¦åˆ é™¤çš„å¹¿å‘Šæ–‡ä»¶ã€‚ä¿ç•™çš„æ–‡ä»¶: {files_kept}")
            return True, "âœ… æœªæ‰¾åˆ°å¹¿å‘Šæ–‡ä»¶ï¼Œæ— éœ€æ¸…ç†ã€‚"

        logger.info(f"å‡†å¤‡åˆ é™¤ä»¥ä¸‹æ–‡ä»¶: {files_to_delete}")

        # 3. Delete identified files
        deleted_count = 0
        delete_errors = []
        for filename_to_delete in files_to_delete:
             delete_payload = {
                "dir": directory_path,
                "names": [filename_to_delete]
            }
        try:
                response_remove = await loop.run_in_executor(
                    None, lambda: requests.post(remove_url, json=delete_payload, headers=headers, timeout=15)
                )
                remove_result = response_remove.json()
                if remove_result.get("code") == 200:
                    logger.info(f"æˆåŠŸåˆ é™¤æ–‡ä»¶: {os.path.join(directory_path, filename_to_delete)}")
                    deleted_count += 1
                else:
                    err_msg = f"åˆ é™¤ '{filename_to_delete}' å¤±è´¥: {remove_result.get('message', 'æœªçŸ¥é”™è¯¯')} (Code: {remove_result.get('code')})"
                    logger.error(err_msg)
                    delete_errors.append(err_msg)
        except Exception as e:
                err_msg = f"åˆ é™¤ '{filename_to_delete}' æ—¶å‘ç”Ÿè¯·æ±‚é”™è¯¯: {e}"
                logger.error(err_msg, exc_info=True)
                delete_errors.append(err_msg)

        except Exception as e: # --- Check this inner except block ---
                # Ensure this except line is correctly indented relative to its 'try'
                err_msg = f"åˆ é™¤ '{filename_to_delete}' æ—¶å‘ç”Ÿè¯·æ±‚é”™è¯¯: {e}"
                 # Ensure the next two lines are correctly indented and have no syntax errors
                logger.error(err_msg, exc_info=True)
                delete_errors.append(err_msg)

        # 4. Report result
        if not delete_errors:
            msg = f"âœ… æˆåŠŸæ¸…ç† {deleted_count} ä¸ªå¹¿å‘Šæ–‡ä»¶ã€‚"
            logger.info(msg + f" ä¿ç•™çš„æ–‡ä»¶: {files_kept}")
            return True, msg
        else:
            msg = f"âš ï¸ æ¸…ç†å®Œæˆï¼Œä½†æœ‰ {len(delete_errors)} ä¸ªæ–‡ä»¶åˆ é™¤å¤±è´¥ (å…±è¯†åˆ« {len(files_to_delete)} ä¸ª)ã€‚æˆåŠŸåˆ é™¤ {deleted_count} ä¸ªã€‚"
            logger.error(msg + f" é”™è¯¯è¯¦æƒ…: {delete_errors}")
            return False, msg

    except requests.exceptions.Timeout:
        msg = f"æ¸…ç†æ“ä½œè¶…æ—¶ (ä¸ Alist é€šä¿¡æ—¶)"
        logger.error(msg)
        return False, f"âŒ æ¸…ç†å¤±è´¥: {msg}"
    except requests.exceptions.RequestException as e:
        msg = f"æ¸…ç†æ“ä½œæ—¶å‘ç”Ÿç½‘ç»œé”™è¯¯: {e}"
        logger.error(msg)
        return False, f"âŒ æ¸…ç†å¤±è´¥: {msg}"
    except Exception as e:
        msg = f"æ¸…ç†æ“ä½œæ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}"
        logger.error(msg, exc_info=True)
        return False, f"âŒ æ¸…ç†å¤±è´¥: {msg}"


# --- Telegram æœºå™¨äººå‘½ä»¤å¤„ç†å‡½æ•° ---

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """å‘é€å¼€å§‹æ¶ˆæ¯"""
    user_id = update.effective_user.id
    if user_id not in ALLOWED_USER_IDS:
         await update.message.reply_text("æŠ±æ­‰ï¼Œæ‚¨æ²¡æœ‰æƒé™ä½¿ç”¨æ­¤æœºå™¨äººã€‚")
         return
    await update.message.reply_text(
        'æ¬¢è¿ä½¿ç”¨ JAV ä¸‹è½½æœºå™¨äººï¼\n'
        'ç›´æ¥å‘é€ç•ªå·ï¼ˆå¦‚ ABC-123ï¼‰æˆ–ç£åŠ›é“¾æ¥ï¼Œæˆ‘ä¼šå¸®ä½ æ·»åŠ åˆ° Alist ç¦»çº¿ä¸‹è½½ã€‚\n'
        '/help æŸ¥çœ‹å¸®åŠ©ã€‚'
    )

async def help_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """å‘é€å¸®åŠ©ä¿¡æ¯"""
    user_id = update.effective_user.id
    if user_id not in ALLOWED_USER_IDS:
         await update.message.reply_text("æŠ±æ­‰ï¼Œæ‚¨æ²¡æœ‰æƒé™ä½¿ç”¨æ­¤æœºå™¨äººã€‚")
         return
    await update.message.reply_text(
        'ä½¿ç”¨æ–¹æ³•ï¼š\n'
        '1. ç›´æ¥å‘é€ç•ªå·ï¼ˆä¾‹å¦‚ï¼š`ABC-123`, `IPX-888`ï¼‰\n'
        '2. ç›´æ¥å‘é€ç£åŠ›é“¾æ¥ï¼ˆä»¥ `magnet:?` å¼€å¤´ï¼‰\n\n'
        '3. ä½¿ç”¨/clean åŠ ç•ªå·åæ¸…ç†å¹¿å‘Šæ–‡ä»¶ï¼ˆä¾‹å¦‚ /clean IPX-888ï¼‰\n\n'
        'æœºå™¨äººä¼šè‡ªåŠ¨æœç´¢ç•ªå·å¯¹åº”çš„ç£åŠ›é“¾æ¥ï¼ˆå¦‚æœè¾“å…¥çš„æ˜¯ç•ªå·ï¼‰ï¼Œç„¶åå°†ç£åŠ›é“¾æ¥æ·»åŠ åˆ° Alist çš„ç¦»çº¿ä¸‹è½½é˜Ÿåˆ—ä¸­ã€‚\n'
        f'å½“å‰é…ç½®çš„ä¸‹è½½ç›®å½•: `{OFFLINE_DOWNLOAD_DIR}`',
        parse_mode='Markdown'
    )

# ç•ªå·æ ¼å¼çš„ç®€å•æ­£åˆ™è¡¨è¾¾å¼ (å¯ä»¥æ ¹æ®éœ€è¦è°ƒæ•´)
# åŒ¹é…å¸¸è§çš„æ ¼å¼ï¼Œå¦‚ XXX-123, XXX123, XXX 123
FANHAO_REGEX = re.compile(r'^[A-Za-z]{2,5}[- ]?\d{2,5}$', re.IGNORECASE)

@restricted # åº”ç”¨æƒé™æ£€æŸ¥å’Œ token è·å–
async def process_message(update: Update, context: ContextTypes.DEFAULT_TYPE, token: str) -> None:
    message_text = update.message.text.strip()
    magnet = None
    search_needed = False
    processing_msg = None # åˆå§‹åŒ– processing_msg
    chat_id = update.effective_chat.id # è·å– chat_id ä»¥ä¾¿å‘é€ action

    if message_text.startswith("magnet:?"):
        logger.info(f"æ”¶åˆ°ç£åŠ›é“¾æ¥: {message_text[:50]}...")
        magnet = message_text
        # å‘é€åˆå§‹æ¶ˆæ¯
        processing_msg = await update.message.reply_text("ğŸ”— æ”¶åˆ°ç£åŠ›é“¾æ¥ï¼Œå‡†å¤‡æ·»åŠ ...")

    elif FANHAO_REGEX.match(message_text):
        logger.info(f"æ”¶åˆ°å¯èƒ½çš„ç•ªå·: {message_text}")
        search_needed = True
        # å‘é€åˆå§‹æ¶ˆæ¯
        processing_msg = await update.message.reply_text(f"ğŸ” æ­£åœ¨æœç´¢ç•ªå·: {message_text}...")

        await context.bot.send_chat_action(chat_id=chat_id, action=ChatAction.TYPING)

        loop = asyncio.get_running_loop()
        try:
            magnet, error_msg = await loop.run_in_executor(
                None, lambda: get_magnet(message_text, SEARCH_URL)
            )
        except Exception as e:
             logger.error(f"æ‰§è¡Œ get_magnet æ—¶å‘ç”Ÿæ„å¤–é”™è¯¯: {e}", exc_info=True)
             magnet, error_msg = None, "æœç´¢è¿‡ç¨‹ä¸­å‘ç”Ÿå†…éƒ¨é”™è¯¯"

        if not magnet:
            await processing_msg.edit_text(f"âŒ æœç´¢å¤±è´¥: {error_msg}")
            return

        await processing_msg.edit_text(f"âœ… å·²æ‰¾åˆ°ç£åŠ›é“¾æ¥ï¼Œæ­£åœ¨æ·»åŠ åˆ° Alist...")

    else:
        logger.warning(f"æ”¶åˆ°æ— æ³•è¯†åˆ«çš„æ¶ˆæ¯æ ¼å¼: {message_text}")
        await update.message.reply_text("æ— æ³•è¯†åˆ«çš„æ¶ˆæ¯æ ¼å¼ã€‚è¯·å‘é€ç•ªå·ï¼ˆå¦‚ ABC-123ï¼‰æˆ–ç£åŠ›é“¾æ¥ã€‚")
        return

    await context.bot.send_chat_action(chat_id=chat_id, action=ChatAction.TYPING)

    success, result_msg = await add_magnet(context, token, magnet)

    if processing_msg:
        await processing_msg.edit_text(result_msg)
    else:
        # å¦‚æœæ˜¯ç›´æ¥å¤„ç†ç£é“¾ä¸”æ²¡æœ‰ç¼–è¾‘å¯¹è±¡ï¼Œåˆ™å›å¤
        await update.message.reply_text(result_msg)
        
        
@restricted # Apply permission check and token injection
async def clean_command(update: Update, context: ContextTypes.DEFAULT_TYPE, token: str) -> None:
    """
    Finds the download directory associated with a code and cleans ad files.
    Usage: /clean <CODE>
    Example: /clean SONE-622
    Searches in OFFLINE_DOWNLOAD_DIR for a folder starting with <CODE>.
    """
    if not context.args:
        await update.message.reply_text(
            "è¯·æä¾›è¦æ¸…ç†çš„ç•ªå·ä»£ç ã€‚\n"
            "ç”¨æ³•: `/clean <ç•ªå·ä»£ç >`\n"
            "ä¾‹å¦‚: `/clean SONE-622`\n"
            f"æœºå™¨äººå°†åœ¨ `{OFFLINE_DOWNLOAD_DIR}` ä¸­æœç´¢åŒ¹é…çš„ç›®å½•è¿›è¡Œæ¸…ç†ã€‚",
            parse_mode='Markdown'
        )
        return

    original_code = context.args[0].strip()
    chat_id = update.effective_chat.id

    logger.info(f"æ”¶åˆ°æ¸…ç†è¯·æ±‚: code='{original_code}', åŸºç¡€ç›®å½•='{OFFLINE_DOWNLOAD_DIR}'")

    # Send initial message and typing action
    processing_msg = await update.message.reply_text(f"ğŸ” æ­£åœ¨æŸ¥æ‰¾ä¸ '{original_code}' åŒ¹é…çš„ä¸‹è½½ç›®å½•...")
    await context.bot.send_chat_action(chat_id=chat_id, action=ChatAction.TYPING)

    # --- Step 1: Find the actual directory ---
    # Pass the BASE Alist URL and the PARENT download directory
    directory_to_clean, find_error = await find_download_directory(token, BASE_URL, OFFLINE_DOWNLOAD_DIR, original_code)

    if find_error:
        await processing_msg.edit_text(f"âŒ æŸ¥æ‰¾ç›®å½•å¤±è´¥: {find_error}")

    # --- Step 2: If directory found, proceed with cleanup ---
    logger.info(f"æ‰¾åˆ°ç›®æ ‡ç›®å½• '{directory_to_clean}'ï¼Œå¼€å§‹æ¸…ç†å¹¿å‘Šæ–‡ä»¶...")
    escaped_path = html.escape(directory_to_clean) # è½¬ä¹‰ HTML ç‰¹æ®Šå­—ç¬¦
    await processing_msg.edit_text(
    f"ğŸ§¹ å·²æ‰¾åˆ°ç›®å½•: <code>{escaped_path}</code>\næ­£åœ¨æ¸…ç†å¹¿å‘Šæ–‡ä»¶...", 
    parse_mode=ParseMode.HTML
)
    await context.bot.send_chat_action(chat_id=chat_id, action=ChatAction.TYPING)

    success, message = await cleanup_ad_files(token, BASE_URL, directory_to_clean, original_code)

    await processing_msg.edit_text(message)


def main() -> None:
    """å¯åŠ¨æœºå™¨äºº"""
    logger.info("å¼€å§‹åˆå§‹åŒ– Telegram æœºå™¨äºº...")

    # åˆ›å»ºåº”ç”¨
    application = Application.builder().token(TELEGRAM_TOKEN).build()

    # æ·»åŠ å¤„ç†ç¨‹åº
    application.add_handler(CommandHandler("start", start))
    application.add_handler(CommandHandler("help", help_command))
    application.add_handler(CommandHandler("clean", clean_command)) # <-- æ·»åŠ è¿™ä¸€è¡Œ
    # Message handler should remain last if it's a catch-all
    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, process_message))

    # å¯åŠ¨æœºå™¨äºº
    logger.info("å¯åŠ¨ Telegram æœºå™¨äººè½®è¯¢...")
    application.run_polling(allowed_updates=Update.ALL_TYPES)

if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        logger.critical(f"ç¨‹åºå¯åŠ¨æˆ–è¿è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿä¸¥é‡é”™è¯¯: {str(e)}", exc_info=True)
        sys.exit(1)
    finally:
        logger.info("Telegram æœºå™¨äººå·²åœæ­¢ã€‚")
